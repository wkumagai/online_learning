# ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆãƒ»ã‚¢ãƒ©ãƒ¼ãƒˆé€šçŸ¥ãƒ»ã‚·ã‚¹ãƒ†ãƒ ç•°å¸¸æ¤œçŸ¥ã®èª¬æ˜

## 1. å„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ãƒ­ã‚°ã‚’é›†ç´„ã™ã‚‹ç†ç”±ã¨æ–¹æ³•

å–å¼•ã‚·ã‚¹ãƒ†ãƒ ã¯è¤‡æ•°ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆå¸‚å ´æƒ…å ±å–å¾—ã€æˆ¦ç•¥å®Ÿè¡Œã€è©•ä¾¡ã€å–å¼•åŸ·è¡Œãªã©ï¼‰ã‹ã‚‰æ§‹æˆã•ã‚Œã¦ãŠã‚Šã€ãã‚Œãã‚ŒãŒç‹¬è‡ªã®ãƒ­ã‚°ã‚’ç”Ÿæˆã—ã¾ã™ã€‚ã“ã‚Œã‚‰ã®ãƒ­ã‚°ã‚’åŠ¹æœçš„ã«é›†ç´„ã™ã‚‹ã“ã¨ã§ã€ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®çŠ¶æ…‹æŠŠæ¡ã€å•é¡Œã®æ—©æœŸç™ºè¦‹ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚

### ãƒ­ã‚°é›†ç´„ã®ä¸»ãªç†ç”±

1. **åŒ…æ‹¬çš„ãªã‚·ã‚¹ãƒ†ãƒ ç›£è¦–**
   - è¤‡æ•°ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®å‹•ä½œã‚’ä¸€å…ƒçš„ã«ç›£è¦–
   - ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«é–“ã®ç›¸äº’ä½œç”¨ã‚„ä¾å­˜é–¢ä¿‚ã®æŠŠæ¡
   - ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨å¥å…¨æ€§ã®è©•ä¾¡

2. **å•é¡Œã®è¿…é€Ÿãªç‰¹å®šã¨è§£æ±º**
   - ã‚¨ãƒ©ãƒ¼ã®æ ¹æœ¬åŸå› ã‚’ç‰¹å®šã™ã‚‹ãŸã‚ã®æ–‡è„ˆæƒ…å ±ã®æä¾›
   - è¤‡æ•°ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã«ã¾ãŸãŒã‚‹å•é¡Œã®ç›¸é–¢é–¢ä¿‚ã®æŠŠæ¡
   - ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã®åŠ¹ç‡åŒ–

3. **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æã¨æœ€é©åŒ–**
   - å„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®å‡¦ç†æ™‚é–“ã‚„åŠ¹ç‡ã®æ¸¬å®š
   - ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã®ç‰¹å®š
   - æœ€é©åŒ–ã®æ©Ÿä¼šã®ç™ºè¦‹

4. **ç›£æŸ»ã¨ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹**
   - å–å¼•æ´»å‹•ã®å®Œå…¨ãªè¨˜éŒ²ã®ç¶­æŒ
   - è¦åˆ¶è¦ä»¶ã¸ã®æº–æ‹ 
   - å•é¡Œç™ºç”Ÿæ™‚ã®äº‹å¾Œåˆ†æ

### ãƒ­ã‚°é›†ç´„ã®æ–¹æ³•

#### 1. æ§‹é€ åŒ–ãƒ­ã‚°å½¢å¼ã®çµ±ä¸€

ã™ã¹ã¦ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã§ä¸€è²«ã—ãŸæ§‹é€ åŒ–ãƒ­ã‚°å½¢å¼ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ã€è§£æã¨ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ãŒå®¹æ˜“ã«ãªã‚Šã¾ã™ã€‚

```python
import logging
import json
from datetime import datetime

class StructuredLogFormatter(logging.Formatter):
    """æ§‹é€ åŒ–ãƒ­ã‚°ãƒ•ã‚©ãƒ¼ãƒãƒƒã‚¿"""
    
    def format(self, record):
        log_data = {
            "timestamp": datetime.utcnow().isoformat(),
            "level": record.levelname,
            "module": record.module,
            "function": record.funcName,
            "line": record.lineno,
            "message": record.getMessage(),
        }
        
        # ä¾‹å¤–æƒ…å ±ãŒã‚ã‚‹å ´åˆã¯è¿½åŠ 
        if record.exc_info:
            log_data["exception"] = self.formatException(record.exc_info)
        
        # ã‚«ã‚¹ã‚¿ãƒ å±æ€§ãŒã‚ã‚Œã°è¿½åŠ 
        if hasattr(record, "extra_data"):
            log_data.update(record.extra_data)
        
        return json.dumps(log_data)

def setup_structured_logging():
    """æ§‹é€ åŒ–ãƒ­ã‚°ã®è¨­å®š"""
    # ãƒ«ãƒ¼ãƒˆãƒ­ã‚¬ãƒ¼ã®è¨­å®š
    root_logger = logging.getLogger()
    root_logger.setLevel(logging.INFO)
    
    # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ãƒãƒ³ãƒ‰ãƒ©
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(StructuredLogFormatter())
    root_logger.addHandler(console_handler)
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒ³ãƒ‰ãƒ©
    file_handler = logging.FileHandler("logs/system.log")
    file_handler.setFormatter(StructuredLogFormatter())
    root_logger.addHandler(file_handler)
```

#### 2. é›†ä¸­ãƒ­ã‚°åé›†ã‚·ã‚¹ãƒ†ãƒ 

è¤‡æ•°ã®ã‚µãƒ¼ãƒãƒ¼ã‚„ãƒ—ãƒ­ã‚»ã‚¹ã‹ã‚‰ãƒ­ã‚°ã‚’åé›†ã™ã‚‹ãŸã‚ã®é›†ä¸­ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚

```python
import os
from logging.handlers import SocketHandler, QueueHandler
import queue
import threading

def setup_centralized_logging(log_server_host, log_server_port):
    """é›†ä¸­ãƒ­ã‚°åé›†ã®è¨­å®š"""
    # ãƒ«ãƒ¼ãƒˆãƒ­ã‚¬ãƒ¼ã®å–å¾—
    root_logger = logging.getLogger()
    
    # ã‚½ã‚±ãƒƒãƒˆãƒãƒ³ãƒ‰ãƒ©ï¼ˆãƒªãƒ¢ãƒ¼ãƒˆãƒ­ã‚°ã‚µãƒ¼ãƒãƒ¼ã¸é€ä¿¡ï¼‰
    socket_handler = SocketHandler(log_server_host, log_server_port)
    root_logger.addHandler(socket_handler)
    
    # éåŒæœŸãƒ­ã‚°å‡¦ç†ã®ãŸã‚ã®ã‚­ãƒ¥ãƒ¼ãƒãƒ³ãƒ‰ãƒ©
    log_queue = queue.Queue(-1)  # ç„¡åˆ¶é™ã‚­ãƒ¥ãƒ¼
    queue_handler = QueueHandler(log_queue)
    root_logger.addHandler(queue_handler)
    
    # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ã‚­ãƒ¥ãƒ¼ã‹ã‚‰ãƒ­ã‚°ã‚’å‡¦ç†ã™ã‚‹ãƒªã‚¹ãƒŠãƒ¼
    listener = logging.handlers.QueueListener(
        log_queue, 
        socket_handler,
        respect_handler_level=True
    )
    listener.start()
    
    return listener  # ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³çµ‚äº†æ™‚ã«stop()ã‚’å‘¼ã¶å¿…è¦ã‚ã‚Š
```

#### 3. ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã®è¿½åŠ 

ãƒ­ã‚°ã«ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã§ã€é–¢é€£ã™ã‚‹ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒªã‚’é–¢é€£ä»˜ã‘ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

```python
import uuid
from contextvars import ContextVar

# ãƒªã‚¯ã‚¨ã‚¹ãƒˆIDã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå¤‰æ•°
request_id_var = ContextVar('request_id', default=None)

class ContextFilter(logging.Filter):
    """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã‚’ãƒ­ã‚°ã«è¿½åŠ ã™ã‚‹ãƒ•ã‚£ãƒ«ã‚¿"""
    
    def filter(self, record):
        # ç¾åœ¨ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆIDã‚’å–å¾—
        request_id = request_id_var.get()
        if request_id:
            record.request_id = request_id
        else:
            record.request_id = str(uuid.uuid4())
        
        return True

def with_request_context(func):
    """é–¢æ•°å®Ÿè¡Œæ™‚ã«æ–°ã—ã„ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿"""
    @functools.wraps(func)
    def wrapper(*args, **kwargs):
        # æ–°ã—ã„ãƒªã‚¯ã‚¨ã‚¹ãƒˆIDã‚’ç”Ÿæˆ
        request_id = str(uuid.uuid4())
        token = request_id_var.set(request_id)
        try:
            return func(*args, **kwargs)
        finally:
            request_id_var.reset(token)
    return wrapper
```

#### 4. ãƒ­ã‚°åˆ†æã¨ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰

åé›†ã—ãŸãƒ­ã‚°ã‚’åˆ†æã—ã€è¦–è¦šåŒ–ã™ã‚‹ãŸã‚ã®ãƒ„ãƒ¼ãƒ«ã‚’å°å…¥ã—ã¾ã™ã€‚

```python
def setup_log_analysis():
    """ãƒ­ã‚°åˆ†æã®è¨­å®š"""
    # Elasticsearchã¸ã®ãƒ­ã‚°é€ä¿¡ãƒãƒ³ãƒ‰ãƒ©
    es_handler = ElasticsearchHandler(
        hosts=[{'host': 'localhost', 'port': 9200}],
        index_name="trading_system_logs"
    )
    
    # Elasticsearchãƒãƒ³ãƒ‰ãƒ©ã‚’ãƒ­ã‚¬ãƒ¼ã«è¿½åŠ 
    root_logger = logging.getLogger()
    root_logger.addHandler(es_handler)
    
    # Kibanaãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã®è¨­å®šæƒ…å ±
    dashboard_url = "http://localhost:5601/app/kibana#/dashboard/trading-system"
    
    return dashboard_url
```

## 2. ãƒ¬ãƒãƒ¼ãƒˆå½¢å¼ã¨ã‚¿ã‚¤ãƒŸãƒ³ã‚°

å–å¼•ã‚·ã‚¹ãƒ†ãƒ ã®çŠ¶æ…‹ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã€ç•°å¸¸ã‚’æŠŠæ¡ã™ã‚‹ãŸã‚ã«ã€æ§˜ã€…ãªå½¢å¼ã®ãƒ¬ãƒãƒ¼ãƒˆã‚’å®šæœŸçš„ã«ç”Ÿæˆã—ã¾ã™ã€‚

### ãƒ¬ãƒãƒ¼ãƒˆå½¢å¼

#### HTMLå½¢å¼

Webãƒ–ãƒ©ã‚¦ã‚¶ã§é–²è¦§å¯èƒ½ãªå¯¾è©±çš„ãªãƒ¬ãƒãƒ¼ãƒˆã§ã™ã€‚ã‚°ãƒ©ãƒ•ã‚„ãƒãƒ£ãƒ¼ãƒˆã‚’å«ã¿ã€ãƒ‰ãƒªãƒ«ãƒ€ã‚¦ãƒ³åˆ†æãŒå¯èƒ½ã§ã™ã€‚

```python
def generate_html_report(data, template_path, output_path):
    """HTMLãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ"""
    import jinja2
    import plotly.express as px
    import plotly.graph_objects as go
    
    # Jinjaãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚¨ãƒ³ã‚¸ãƒ³ã®è¨­å®š
    env = jinja2.Environment(
        loader=jinja2.FileSystemLoader(os.path.dirname(template_path))
    )
    template = env.get_template(os.path.basename(template_path))
    
    # Plotlyã§ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆ
    performance_fig = px.line(
        data["performance_history"], 
        x="date", 
        y="portfolio_value",
        title="Portfolio Performance"
    )
    performance_chart = performance_fig.to_html(full_html=False)
    
    # å–å¼•åˆ†å¸ƒã‚’è¡¨ç¤ºã™ã‚‹ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
    trades_fig = px.histogram(
        data["trades"], 
        x="return_pct",
        color="strategy",
        title="Trade Return Distribution"
    )
    trades_chart = trades_fig.to_html(full_html=False)
    
    # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«ãƒ‡ãƒ¼ã‚¿ã¨ã‚°ãƒ©ãƒ•ã‚’æ¸¡ã—ã¦HTMLã‚’ç”Ÿæˆ
    html_content = template.render(
        title="Trading System Report",
        generation_time=datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        summary=data["summary"],
        performance_chart=performance_chart,
        trades_chart=trades_chart,
        positions=data["current_positions"],
        recent_trades=data["recent_trades"],
        metrics=data["metrics"]
    )
    
    # HTMLãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    with open(output_path, "w") as f:
        f.write(html_content)
    
    return output_path
```

#### PDFå½¢å¼

å°åˆ·ã‚„å…±æœ‰ã«é©ã—ãŸé™çš„ãªãƒ¬ãƒãƒ¼ãƒˆå½¢å¼ã§ã™ã€‚

```python
def generate_pdf_report(data, template_path, output_path):
    """PDFãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ"""
    import weasyprint
    
    # ã¾ãšHTMLãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
    html_path = output_path.replace(".pdf", ".html")
    generate_html_report(data, template_path, html_path)
    
    # HTMLã‹ã‚‰PDFã‚’ç”Ÿæˆ
    weasyprint.HTML(html_path).write_pdf(output_path)
    
    return output_path
```

#### JSON/CSVå½¢å¼

ãƒ‡ãƒ¼ã‚¿åˆ†æã‚„ã‚·ã‚¹ãƒ†ãƒ é–“é€£æºã«é©ã—ãŸæ©Ÿæ¢°å¯èª­å½¢å¼ã§ã™ã€‚

```python
def generate_data_export(data, format_type, output_path):
    """ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã®ç”Ÿæˆ"""
    if format_type == "json":
        # JSONå½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
        with open(output_path, "w") as f:
            json.dump(data, f, indent=2, default=str)
    
    elif format_type == "csv":
        # CSVå½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆï¼ˆè¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        
        # å„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’åˆ¥ã€…ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        for key, dataset in data.items():
            if isinstance(dataset, list) or isinstance(dataset, pd.DataFrame):
                if isinstance(dataset, list) and dataset and isinstance(dataset[0], dict):
                    df = pd.DataFrame(dataset)
                elif isinstance(dataset, pd.DataFrame):
                    df = dataset
                else:
                    continue
                
                csv_path = os.path.join(
                    os.path.dirname(output_path),
                    f"{key}_{os.path.basename(output_path)}"
                )
                df.to_csv(csv_path, index=False)
    
    return output_path
```

### ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¿ã‚¤ãƒŸãƒ³ã‚°

#### å®šæœŸãƒ¬ãƒãƒ¼ãƒˆ

- **æ—¥æ¬¡ãƒ¬ãƒãƒ¼ãƒˆ**: æ¯æ—¥ã®å–å¼•çµ‚äº†å¾Œã«ç”Ÿæˆï¼ˆå–å¼•ã‚µãƒãƒªãƒ¼ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™ï¼‰
- **é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆ**: é€±æœ«ã«ç”Ÿæˆï¼ˆé€±é–“ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã€æˆ¦ç•¥åˆ†æï¼‰
- **æœˆæ¬¡ãƒ¬ãƒãƒ¼ãƒˆ**: æœˆæœ«ã«ç”Ÿæˆï¼ˆè©³ç´°ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æã€ãƒªã‚¹ã‚¯æŒ‡æ¨™ï¼‰

```python
def schedule_periodic_reports():
    """å®šæœŸãƒ¬ãƒãƒ¼ãƒˆã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°"""
    import schedule
    
    # æ—¥æ¬¡ãƒ¬ãƒãƒ¼ãƒˆï¼ˆå–å¼•æ—¥ã®çµ‚äº†å¾Œï¼‰
    schedule.every().day.at("16:30").do(
        generate_daily_report,
        output_dir="reports/daily"
    )
    
    # é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆï¼ˆé‡‘æ›œæ—¥ã®å–å¼•çµ‚äº†å¾Œï¼‰
    schedule.every().friday.at("17:00").do(
        generate_weekly_report,
        output_dir="reports/weekly"
    )
    
    # æœˆæ¬¡ãƒ¬ãƒãƒ¼ãƒˆï¼ˆæœˆæœ«ï¼‰
    schedule.every().month.at("23:59").do(
        generate_monthly_report,
        output_dir="reports/monthly"
    )
    
    # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ã®å®Ÿè¡Œ
    while True:
        schedule.run_pending()
        time.sleep(60)
```

#### ã‚¤ãƒ™ãƒ³ãƒˆãƒˆãƒªã‚¬ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆ

- **å–å¼•å®Ÿè¡Œå¾Œ**: é‡è¦ãªå–å¼•ãŒå®Ÿè¡Œã•ã‚ŒãŸå¾Œã«ç”Ÿæˆ
- **é–¾å€¤è¶…éæ™‚**: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™ãŒç‰¹å®šã®é–¾å€¤ã‚’è¶…ãˆãŸå ´åˆ
- **ç•°å¸¸æ¤œçŸ¥æ™‚**: ã‚·ã‚¹ãƒ†ãƒ ç•°å¸¸ãŒæ¤œå‡ºã•ã‚ŒãŸå ´åˆ

```python
def register_event_triggered_reports(event_bus):
    """ã‚¤ãƒ™ãƒ³ãƒˆãƒˆãƒªã‚¬ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã®ç™»éŒ²"""
    
    # å–å¼•å®Ÿè¡Œå¾Œã®ãƒ¬ãƒãƒ¼ãƒˆ
    @event_bus.on("trade.executed")
    def on_trade_executed(trade_data):
        if trade_data["notional_value"] > 10000:  # å¤§å£å–å¼•ã®å ´åˆ
            generate_trade_report(trade_data, "reports/trades")
    
    # é–¾å€¤è¶…éæ™‚ã®ãƒ¬ãƒãƒ¼ãƒˆ
    @event_bus.on("performance.updated")
    def on_performance_updated(performance_data):
        # ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³ãŒ5%ã‚’è¶…ãˆãŸå ´åˆ
        if performance_data["drawdown"] < -0.05:
            generate_drawdown_report(performance_data, "reports/alerts")
    
    # ç•°å¸¸æ¤œçŸ¥æ™‚ã®ãƒ¬ãƒãƒ¼ãƒˆ
    @event_bus.on("anomaly.detected")
    def on_anomaly_detected(anomaly_data):
        generate_anomaly_report(anomaly_data, "reports/anomalies")
```

#### ã‚ªãƒ³ãƒ‡ãƒãƒ³ãƒ‰ãƒ¬ãƒãƒ¼ãƒˆ

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¦æ±‚ã«å¿œã˜ã¦ç”Ÿæˆã•ã‚Œã‚‹ã‚«ã‚¹ã‚¿ãƒ ãƒ¬ãƒãƒ¼ãƒˆã§ã™ã€‚

```python
def generate_on_demand_report(report_type, parameters, output_format="html"):
    """ã‚ªãƒ³ãƒ‡ãƒãƒ³ãƒ‰ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ"""
    # ãƒ¬ãƒãƒ¼ãƒˆã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸãƒ‡ãƒ¼ã‚¿åé›†
    if report_type == "performance":
        data = collect_performance_data(
            start_date=parameters.get("start_date"),
            end_date=parameters.get("end_date"),
            strategies=parameters.get("strategies")
        )
        template_path = "templates/performance_report.html"
    
    elif report_type == "risk":
        data = collect_risk_data(
            start_date=parameters.get("start_date"),
            end_date=parameters.get("end_date"),
            metrics=parameters.get("metrics")
        )
        template_path = "templates/risk_report.html"
    
    elif report_type == "strategy":
        data = collect_strategy_data(
            strategy_id=parameters.get("strategy_id"),
            time_period=parameters.get("time_period")
        )
        template_path = "templates/strategy_report.html"
    
    else:
        raise ValueError(f"Unknown report type: {report_type}")
    
    # å‡ºåŠ›ãƒ‘ã‚¹ã®ç”Ÿæˆ
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_path = f"reports/on_demand/{report_type}_{timestamp}.{output_format}"
    
    # ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ
    if output_format == "html":
        return generate_html_report(data, template_path, output_path)
    elif output_format == "pdf":
        return generate_pdf_report(data, template_path, output_path)
    elif output_format in ["json", "csv"]:
        return generate_data_export(data, output_format, output_path)
    else:
        raise ValueError(f"Unsupported output format: {output_format}")
```

## 3. ã‚¢ãƒ©ãƒ¼ãƒˆé€šçŸ¥ï¼ˆãƒ¡ãƒ¼ãƒ«/Slackï¼‰ã®ä¾‹

ã‚·ã‚¹ãƒ†ãƒ ã®é‡è¦ãªã‚¤ãƒ™ãƒ³ãƒˆã‚„ç•°å¸¸ã‚’æ¤œå‡ºã—ãŸå ´åˆã€é–¢ä¿‚è€…ã«è¿…é€Ÿã«é€šçŸ¥ã™ã‚‹ãŸã‚ã®ã‚¢ãƒ©ãƒ¼ãƒˆæ©Ÿèƒ½ãŒå¿…è¦ã§ã™ã€‚

### ã‚¢ãƒ©ãƒ¼ãƒˆã®ç¨®é¡

1. **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚¢ãƒ©ãƒ¼ãƒˆ**: ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³ã€æ€¥æ¿€ãªæç›Šå¤‰å‹•ãªã©
2. **ãƒªã‚¹ã‚¯ã‚¢ãƒ©ãƒ¼ãƒˆ**: ãƒã‚¸ã‚·ãƒ§ãƒ³é›†ä¸­ã€ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ä¸Šæ˜‡ãªã©
3. **ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ©ãƒ¼ãƒˆ**: APIéšœå®³ã€ãƒ‡ãƒ¼ã‚¿ç•°å¸¸ã€å‡¦ç†é…å»¶ãªã©
4. **å–å¼•ã‚¢ãƒ©ãƒ¼ãƒˆ**: å¤§å£å–å¼•ã€ç‰¹å®šæ¡ä»¶ã®å–å¼•ã‚·ã‚°ãƒŠãƒ«ãªã©

### é€šçŸ¥ãƒãƒ£ãƒãƒ«

#### ãƒ¡ãƒ¼ãƒ«é€šçŸ¥

```python
def send_email_alert(recipients, subject, message, attachments=None):
    """ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ©ãƒ¼ãƒˆã®é€ä¿¡"""
    import smtplib
    from email.mime.multipart import MIMEMultipart
    from email.mime.text import MIMEText
    from email.mime.application import MIMEApplication
    
    # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šã‚’èª­ã¿è¾¼ã¿
    smtp_server = os.environ.get("SMTP_SERVER")
    smtp_port = int(os.environ.get("SMTP_PORT", 587))
    smtp_user = os.environ.get("SMTP_USER")
    smtp_password = os.environ.get("SMTP_PASSWORD")
    sender = os.environ.get("ALERT_SENDER", "trading-system@example.com")
    
    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ä½œæˆ
    msg = MIMEMultipart()
    msg["From"] = sender
    msg["To"] = ", ".join(recipients)
    msg["Subject"] = subject
    
    # æœ¬æ–‡ã®è¿½åŠ 
    msg.attach(MIMEText(message, "html"))
    
    # æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã®è¿½åŠ 
    if attachments:
        for attachment in attachments:
            with open(attachment, "rb") as f:
                part = MIMEApplication(f.read(), Name=os.path.basename(attachment))
            part["Content-Disposition"] = f'attachment; filename="{os.path.basename(attachment)}"'
            msg.attach(part)
    
    # ãƒ¡ãƒ¼ãƒ«ã®é€ä¿¡
    with smtplib.SMTP(smtp_server, smtp_port) as server:
        server.starttls()
        server.login(smtp_user, smtp_password)
        server.send_message(msg)
    
    logger.info(f"Email alert sent to {len(recipients)} recipients: {subject}")
```

#### Slacké€šçŸ¥

```python
def send_slack_alert(channel, message, attachments=None):
    """Slackã‚¢ãƒ©ãƒ¼ãƒˆã®é€ä¿¡"""
    import requests
    
    # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰Slack Webhook URLã‚’èª­ã¿è¾¼ã¿
    webhook_url = os.environ.get("SLACK_WEBHOOK_URL")
    
    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ã®ä½œæˆ
    payload = {
        "channel": channel,
        "text": message,
        "attachments": []
    }
    
    # æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã®è¿½åŠ 
    if attachments:
        for attachment in attachments:
            payload["attachments"].append(attachment)
    
    # Webhookã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡
    response = requests.post(
        webhook_url,
        json=payload,
        headers={"Content-Type": "application/json"}
    )
    
    if response.status_code == 200:
        logger.info(f"Slack alert sent to {channel}")
    else:
        logger.error(f"Failed to send Slack alert: {response.status_code} {response.text}")
```

### ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®šä¾‹

```python
def configure_alerts(alert_manager):
    """ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®šã®æ§‹æˆ"""
    
    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚¢ãƒ©ãƒ¼ãƒˆ
    alert_manager.add_alert(
        name="significant_drawdown",
        condition=lambda data: data["drawdown"] < -0.1,  # 10%ä»¥ä¸Šã®ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³
        message="âš ï¸ Significant drawdown detected: {drawdown:.2%}",
        channels=["email", "slack"],
        recipients=["trading-team@example.com"],
        slack_channel="#trading-alerts",
        severity="high"
    )
    
    # ãƒªã‚¹ã‚¯ã‚¢ãƒ©ãƒ¼ãƒˆ
    alert_manager.add_alert(
        name="position_concentration",
        condition=lambda data: data["max_position_pct"] > 0.3,  # 30%ä»¥ä¸Šã®é›†ä¸­
        message="âš ï¸ Position concentration detected: {symbol} at {max_position_pct:.2%}",
        channels=["slack"],
        slack_channel="#risk-alerts",
        severity="medium"
    )
    
    # ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ©ãƒ¼ãƒˆ
    alert_manager.add_alert(
        name="api_failure",
        condition=lambda data: data["consecutive_failures"] >= 3,  # 3å›é€£ç¶šå¤±æ•—
        message="ğŸš¨ API connection failure: {service} - {error_message}",
        channels=["email", "slack", "sms"],
        recipients=["sysadmin@example.com", "trading-team@example.com"],
        slack_channel="#system-alerts",
        severity="critical"
    )
    
    # å–å¼•ã‚¢ãƒ©ãƒ¼ãƒˆ
    alert_manager.add_alert(
        name="large_trade",
        condition=lambda data: data["trade_value"] > 50000,  # 5ä¸‡ãƒ‰ãƒ«ä»¥ä¸Šã®å–å¼•
        message="â„¹ï¸ Large trade executed: {action} {quantity} {symbol} @ {price}",
        channels=["slack"],
        slack_channel="#trading-activity",
        severity="info"
    )
```

### ã‚¢ãƒ©ãƒ¼ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®å®Ÿè£…

```python
class AlertManager:
    """ã‚¢ãƒ©ãƒ¼ãƒˆç®¡ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.alerts = {}
        self.notification_handlers = {
            "email": send_email_alert,
            "slack": send_slack_alert,
            "sms": send_sms_alert
        }
    
    def add_alert(self, name, condition, message, channels, **kwargs):
        """ã‚¢ãƒ©ãƒ¼ãƒˆã®è¿½åŠ """
        self.alerts[name] = {
            "condition": condition,
            "message": message,
            "channels": channels,
            "config": kwargs,
            "last_triggered": None,
            "trigger_count": 0
        }
    
    def check_alerts(self, data_context):
        """ã‚¢ãƒ©ãƒ¼ãƒˆæ¡ä»¶ã®ãƒã‚§ãƒƒã‚¯"""
        triggered_alerts = []
        
        for name, alert in self.alerts.items():
            try:
                # æ¡ä»¶ã®ãƒã‚§ãƒƒã‚¯
                if alert["condition"](data_context):
                    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
                    message = alert["message"].format(**data_context)
                    
                    # é€šçŸ¥ã®é€ä¿¡
                    self._send_notifications(name, message, alert, data_context)
                    
                    # ãƒˆãƒªã‚¬ãƒ¼æƒ…å ±ã®æ›´æ–°
                    alert["last_triggered"] = datetime.now()
                    alert["trigger_count"] += 1
                    
                    triggered_alerts.append(name)
            except Exception as e:
                logger.error(f"Error checking alert {name}: {str(e)}")
        
        return triggered_alerts
    
    def _send_notifications(self, alert_name, message, alert, data_context):
        """é€šçŸ¥ã®é€ä¿¡"""
        for channel in alert["channels"]:
            if channel in self.notification_handlers:
                try:
                    handler = self.notification_handlers[channel]
                    
                    # ãƒãƒ£ãƒãƒ«å›ºæœ‰ã®è¨­å®šã‚’å–å¾—
                    channel_config = {
                        k.replace(f"{channel}_", ""): v 
                        for k, v in alert["config"].items() 
                        if k.startswith(f"{channel}_")
                    }
                    
                    # å…±é€šè¨­å®šã‚’è¿½åŠ 
                    channel_config.update({
                        k: v for k, v in alert["config"].items() 
                        if not any(k.startswith(f"{c}_") for c in self.notification_handlers)
                    })
                    
                    # é€šçŸ¥ã®é€ä¿¡
                    handler(message=message, **channel_config)
                    
                except Exception as e:
                    logger.error(f"Error sending {channel} notification for alert {alert_name}: {str(e)}")
```

## 4. ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—ã‚„APIéšœå®³ãªã©ã‚·ã‚¹ãƒ†ãƒ ç•°å¸¸ã®æ¤œçŸ¥æ–¹æ³•

å–å¼•ã‚·ã‚¹ãƒ†ãƒ ã®å®‰å®šæ€§ã¨ä¿¡é ¼æ€§ã‚’ç¢ºä¿ã™ã‚‹ãŸã‚ã«ã¯ã€æ§˜ã€…ãªã‚·ã‚¹ãƒ†ãƒ ç•°å¸¸ã‚’æ—©æœŸã«æ¤œçŸ¥ã™ã‚‹ä»•çµ„ã¿ãŒå¿…è¦ã§ã™ã€‚

### ä¸»ãªã‚·ã‚¹ãƒ†ãƒ ç•°å¸¸ã®ç¨®é¡

1. **ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—**: å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã€ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã‚¨ãƒ©ãƒ¼
2. **APIéšœå®³**: å–å¼•APIã€ãƒ‡ãƒ¼ã‚¿APIã®æ¥ç¶šå•é¡Œã‚„å¿œç­”ã‚¨ãƒ©ãƒ¼
3. **å‡¦ç†é…å»¶**: æ³¨æ–‡å‡¦ç†ã€ã‚·ã‚°ãƒŠãƒ«ç”Ÿæˆãªã©ã®å‡¦ç†æ™‚é–“ç•°å¸¸
4. **ãƒªã‚½ãƒ¼ã‚¹æ¯æ¸‡**: ãƒ¡ãƒ¢ãƒªã€CPUã€ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ã®ä¸è¶³
5. **ãƒ‡ãƒ¼ã‚¿ç•°å¸¸**: ç•°å¸¸ãªä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã€ä¸æ•´åˆãªãƒ‡ãƒ¼ã‚¿

### ç•°å¸¸æ¤œçŸ¥ã®æ–¹æ³•

#### ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯

å®šæœŸçš„ã«ã‚·ã‚¹ãƒ†ãƒ ã®å„ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®çŠ¶æ…‹ã‚’ç¢ºèªã—ã¾ã™ã€‚

```python
def setup_health_checks(components, check_interval=60):
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã®è¨­å®š"""
    
    def run_health_checks():
        """ã™ã¹ã¦ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œ"""
        results = {}
        
        for name, component in components.items():
            try:
                # ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ãƒ¡ã‚½ãƒƒãƒ‰ã‚’å‘¼ã³å‡ºã—
                status = component.check_health()
                results[name] = {
                    "status": status["status"],
                    "details": status.get("details", {}),
                    "timestamp": datetime.now()
                }
                
                # ç•°å¸¸ãŒã‚ã‚Œã°é€šçŸ¥
                if status["status"] != "healthy":
                    alert_manager.check_alerts({
                        "component": name,
                        "status": status["status"],
                        "details": status.get("details", {}),
                        "error_message": status.get("message", "Unknown error")
                    })
            
            except Exception as e:
                results[name] = {
                    "status": "error",
                    "details": {"exception": str(e)},
                    "timestamp": datetime.now()
                }
                
                # ä¾‹å¤–ãŒç™ºç”Ÿã—ãŸå ´åˆã‚‚é€šçŸ¥
                alert_manager.check_alerts({
                    "component": name,
                    "status": "error",
                    "details": {"exception": str(e)},
                    "error_message": str(e)
                })
        
        # ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯çµæœã®ä¿å­˜
        store_health_check_results(results)
        
        return results
    
    # å®šæœŸçš„ãªãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°
    import threading
    
    def health_check_worker():
        while True:
            run_health_checks()
            time.sleep(check_interval)
    
    # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¹ãƒ¬ãƒƒãƒ‰ã§ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œ
    thread = threading.Thread(target=health_check_worker, daemon=True)
    thread.start()
    
    return thread
```

#### ç•°å¸¸æ¤œçŸ¥ãƒ«ãƒ¼ãƒ«

ãƒ‡ãƒ¼ã‚¿ã‚„å‡¦ç†çµæœã«å¯¾ã—ã¦ç•°å¸¸æ¤œçŸ¥ãƒ«ãƒ¼ãƒ«ã‚’é©ç”¨ã—ã¾ã™ã€‚

```python
def setup_anomaly_detection_rules():
    """ç•°å¸¸æ¤œçŸ¥ãƒ«ãƒ¼ãƒ«ã®è¨­å®š"""
    rules = []
    
    # ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã®ç•°å¸¸æ¤œçŸ¥ãƒ«ãƒ¼ãƒ«
    rules.append({
        "name": "price_spike",
        "target": "market_data",
        "condition": lambda data: abs(data["return_pct"]) > 0.1,  # 10%ä»¥ä¸Šã®ä¾¡æ ¼å¤‰å‹•
        "message": "Abnormal price movement detected for {symbol}: {return_pct:.2%}",
        "severity": "medium"
    })
    
    # APIå¿œç­”æ™‚é–“ã®ç•°å¸¸æ¤œçŸ¥ãƒ«ãƒ¼ãƒ«
    rules.append({
        "name": "api_latency",
        "target": "api_metrics",
        "condition": lambda data: data["response_time"] > 2.0,  # 2ç§’ä»¥ä¸Šã®å¿œç­”æ™‚é–“
        "message": "High API latency detected: {response_time:.2f}s for {endpoint}",
        "severity": "low"
    })
    
    # æ³¨æ–‡å‡¦ç†ã®ç•°å¸¸æ¤œçŸ¥ãƒ«ãƒ¼ãƒ«
    rules.append({
        "name": "order_failure_rate",
        "target": "order_metrics",
        "condition": lambda data: data["failure_rate"] > 0.2,  # 20%ä»¥ä¸Šã®å¤±æ•—ç‡
        "message": "High order failure rate: {failure_rate:.2%}",
        "severity": "high"
    })
    
    # ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ã®ç•°å¸¸æ¤œçŸ¥ãƒ«ãƒ¼ãƒ«
    rules.append({
        "name": "data_consistency",
        "target": "data_validation",
        "condition": lambda data: len(data["inconsistencies"]) > 0,
        "message": "Data inconsistencies detected: {inconsistencies}",
        "severity": "high"
    })
    
    return rules
```

#### çµ±è¨ˆçš„ç•°å¸¸æ¤œçŸ¥

éå»ã®ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦çµ±è¨ˆçš„ã«ç•°å¸¸ã‚’æ¤œå‡ºã—ã¾ã™ã€‚

```python
def setup_statistical_anomaly_detection(data_collector, config):
    """çµ±è¨ˆçš„ç•°å¸¸æ¤œçŸ¥ã®è¨­å®š"""
    from sklearn.ensemble import IsolationForest
    import numpy as np
    
    # ç•°å¸¸æ¤œçŸ¥ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
    models = {}
    
    # å„ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚¿ã‚¤ãƒ—ã«å¯¾ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆ
    for metric_type, metric_config in config.items():
        # éå»ãƒ‡ãƒ¼ã‚¿ã®åé›†
        historical_data = data_collector.get_historical_data(
            metric_type=metric_type,
            lookback_period=metric_config["lookback_period"]
        )
        
        if len(historical_data) >= 100:  # ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã®ã¿
            # ç‰¹å¾´é‡ã®æŠ½å‡º
            features = []
            for record in historical_data:
                feature_vector = []
                for feature in metric_config["features"]:
                    feature_vector.append(record.get(feature, 0))
                features.append(feature_vector)
            
            # Isolation Forestãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’
            model = IsolationForest(
                contamination=metric_config.get("contamination", 0.05),
                random_state=42
            )
            model.fit(features)
            
            # ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜
            models[metric_type] = {
                "model": model,
                "features": metric_config["features"],
                "threshold": metric_config.get("threshold", -0.5)
            }
    
    def detect_anomalies(new_data):
        """æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã®ç•°å¸¸æ¤œçŸ¥"""
        results = {}
        
        for metric_type, model_info in models.items():
            if metric_type in new_data:
                # ç‰¹å¾´é‡ã®æŠ½å‡º
                features = []
                for record in new_data[metric_type]:
                    feature_vector = []
                    for feature in model_info["features"]:
                        feature_vector.append(record.get(feature, 0))
                    features.append(feature_vector)
                
                if features:
                    # ç•°å¸¸ã‚¹ã‚³ã‚¢ã®è¨ˆç®—
                    scores = model_info["model"].decision_function(features)
                    
                    # ç•°å¸¸ã®æ¤œå‡º
                    anomalies = []
                    for i, score in enumerate(scores):
                        if score < model_info["threshold"]:
                            anomalies.append({
                                "record": new_data[metric_type][i],
                                "score": score,
                                "timestamp": datetime.now()
                            })
                    
                    results[metric_type] = anomalies
        
        return results
    
    return detect_anomalies
```

#### ç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰

ã‚·ã‚¹ãƒ†ãƒ ã®çŠ¶æ…‹ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ç›£è¦–ã™ã‚‹ãŸã‚ã®ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚’æä¾›ã—ã¾ã™ã€‚

```python
def setup_monitoring_dashboard(port=8050):
    """ç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã®è¨­å®š"""
    import dash
    from dash import dcc, html
    import plotly.graph_objs as go
    
    # Dashã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®åˆæœŸåŒ–
    app = dash.Dash(__name__)
    
    # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã®å®šç¾©
    app.layout = html.Div([
        html.H1("Trading System Monitoring"),
        
        # ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ã®æ¦‚è¦
        html.Div([
            html.H2("System Status"),
            html.Div(id="system-status")
        ]),
        
        # ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
        html.Div([
            html.H2("Component Health"),
            html.Div(id="component-health")
        ]),
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        html.Div([
            html.H2("Performance Metrics"),
            dcc.Graph(id="performance-graph")
        ]),
        
        # APIå¿œç­”æ™‚é–“
        html.Div([
            html.H2("API Response Times"),
            dcc.Graph(id="api-latency-graph")
        ]),
        
        # ç•°å¸¸æ¤œçŸ¥çµæœ
        html.Div([
            html.H2("Anomaly Detection"),
            html.Div(id="anomaly-list")
        ]),
        
        # è‡ªå‹•æ›´æ–°ã®ãŸã‚ã®é–“éš”è¨­å®š
        dcc.Interval(
            id="interval-component",
            interval=30 * 1000,  # 30ç§’ã”ã¨ã«æ›´æ–°
            n_intervals=0
        )
    ])
    
    # ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã®å®šç¾©
    @app.callback(
        [
            dash.dependencies.Output("system-status", "children"),
            dash.dependencies.Output("component-health", "children"),
            dash.dependencies.Output("performance-graph", "figure"),
            dash.dependencies.Output("api-latency-graph", "figure"),
            dash.dependencies.Output("anomaly-list", "children")
        ],
        [dash.dependencies.Input("interval-component", "n_intervals")]
    )
    def update_dashboard(n):
        # ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ãƒ‡ãƒ¼ã‚¿ã®å–å¾—
        system_status = get_system_status()
        
        # ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆãƒ˜ãƒ«ã‚¹ãƒ‡ãƒ¼ã‚¿ã®å–å¾—
        component_health = get_component_health()
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ã®å–å¾—
        performance_data = get_performance_data()
        
        # APIå¿œç­”æ™‚é–“ãƒ‡ãƒ¼ã‚¿ã®å–å¾—
        api_latency_data = get_api_latency_data()
        
        # ç•°å¸¸æ¤œçŸ¥çµæœã®å–å¾—
        anomalies = get_anomalies()
        
        # ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ã®è¡¨ç¤º
        status_display = html.Div([
            html.P(f"Overall Status: {system_status['overall_status']}"),
            html.P(f"Last Updated: {system_status['last_updated']}"),
            html.P(f"Active Alerts: {system_status['active_alerts']}")
        ])
        
        # ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆãƒ˜ãƒ«ã‚¹ã®è¡¨ç¤º
        health_items = []
        for component, status in component_health.items():
            health_items.append(html.Div([
                html.H4(component),
                html.P(f"Status: {status['status']}"),
                html.P(f"Last Check: {status['last_check']}")
            ]))
        health_display = html.Div(health_items)
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚°ãƒ©ãƒ•ã®ä½œæˆ
        performance_fig = go.Figure()
        performance_fig.add_trace(go.Scatter(
            x=[d["timestamp"] for d in performance_data],
            y=[d["portfolio_value"] for d in performance_data],
            mode="lines",
            name="Portfolio Value"
        ))
        
        # APIå¿œç­”æ™‚é–“ã‚°ãƒ©ãƒ•ã®ä½œæˆ
        api_fig = go.Figure()
        for endpoint, data in api_latency_data.items():
            api_fig.add_trace(go.Scatter(
                x=[d["timestamp"] for d in data],
                y=[d["response_time"] for d in data],
                mode="lines",
                name=endpoint
            ))
        
        # ç•°å¸¸ãƒªã‚¹ãƒˆã®è¡¨ç¤º
        anomaly_items = []
        for anomaly in anomalies:
            anomaly_items.append(html.Div([
                html.H4(anomaly["type"]),
                html.P(f"Detected at: {anomaly['timestamp']}"),
                html.P(f"Details: {anomaly['details']}")
            ]))
        anomaly_display = html.Div(anomaly_items)
        
        return status_display, health_display, performance_fig, api_fig, anomaly_display
    
    # ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã®èµ·å‹•
    import threading
    
    def run_dashboard():
        app.run_server(debug=False, port=port)
    
    # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¹ãƒ¬ãƒƒãƒ‰ã§ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚’å®Ÿè¡Œ
    thread = threading.Thread(target=run_dashboard, daemon=True)
    thread.start()
    
    return f"http://localhost:{port}"
```

é©åˆ‡ãªãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã¨ã‚¢ãƒ©ãƒ¼ãƒˆé€šçŸ¥ã®ä»•çµ„ã¿ã‚’å®Ÿè£…ã™ã‚‹ã“ã¨ã§ã€å–å¼•ã‚·ã‚¹ãƒ†ãƒ ã®çŠ¶æ…‹ã‚’å¸¸ã«æŠŠæ¡ã—ã€å•é¡ŒãŒç™ºç”Ÿã—ãŸå ´åˆã«è¿…é€Ÿã«å¯¾å¿œã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã¾ãŸã€å®šæœŸçš„ãªãƒ¬ãƒãƒ¼ãƒˆã«ã‚ˆã£ã¦ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’åˆ†æã—ã€ç¶™ç¶šçš„ãªæ”¹å–„ã«ã¤ãªã’ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚